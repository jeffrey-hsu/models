{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specialist Convolutional Neural Network Models\n",
    "\n",
    "In this notebook we build several CNN models each trained to predict different facial keypoint sets. The rationale for such approach is that each keypoint contains different number of label observations. Some images show face on the side, thus not all keypoints are revealed. In order to fully utilize labels, other than just examples where full set of keypoints are marked, keypoints close to each other and which number of observations are relatively close are trained with a CNN. This gives us several CNN models. The final prediction is done via all CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n",
      "float64\n",
      "3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from six.moves import cPickle\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.pool import pool_2d\n",
    "\n",
    "import conv_net_helper as helper\n",
    "\n",
    "print(theano.config.device)\n",
    "print(theano.config.floatX)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training Data and Create Training and Dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6042\n",
      "Number of dev examples: 1007\n"
     ]
    }
   ],
   "source": [
    "TRAIN = \"../../../data/facial_keypoints/training.csv\"\n",
    "TEST = \"../../../data/facial_keypoints/test.csv\"\n",
    "\n",
    "rawdata = helper.load_data(TRAIN)\n",
    "X, Y = helper.loadXY(rawdata)\n",
    "num_dev = int(len(X)/7)\n",
    "train_data, train_labels = X[num_dev:], Y[num_dev:]\n",
    "dev_data, dev_labels = X[:num_dev], Y[:num_dev]\n",
    "\n",
    "print(\"Number of training examples:\", len(train_data))\n",
    "print(\"Number of dev examples:\", len(dev_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column names of keypoint sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['eye_ct', 'eye_cr', 'eyebrow', 'nose', 'mouth_cr', 'mouth_ct_top', 'mouth_ct_bottom'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_keypoints = (rawdata.columns.values).tolist()[:-1]\n",
    "cols_dict = {\n",
    "    \"eye_ct\" : [\"left_eye_center_x\", \"left_eye_center_y\",\n",
    "                \"right_eye_center_x\", \"right_eye_center_y\"],\n",
    "    \"eye_cr\" : [\"left_eye_inner_corner_x\", \"left_eye_inner_corner_y\",\n",
    "                \"left_eye_outer_corner_x\", \"left_eye_outer_corner_y\",\n",
    "                \"right_eye_inner_corner_x\", \"right_eye_inner_corner_y\",\n",
    "                \"right_eye_outer_corner_x\", \"right_eye_outer_corner_y\"],\n",
    "    \"eyebrow\" : [\"left_eyebrow_inner_end_x\", \"left_eyebrow_inner_end_y\",\n",
    "                 \"left_eyebrow_outer_end_x\", \"left_eyebrow_outer_end_y\",\n",
    "                 \"right_eyebrow_inner_end_x\", \"right_eyebrow_inner_end_y\",\n",
    "                 \"right_eyebrow_outer_end_x\", \"right_eyebrow_outer_end_y\"],\n",
    "    \"nose\" : [\"nose_tip_x\", \"nose_tip_y\"],\n",
    "    \"mouth_cr\" : [\"mouth_left_corner_x\", \"mouth_left_corner_y\",\n",
    "                           \"mouth_right_corner_x\", \"mouth_right_corner_y\"],\n",
    "    \"mouth_ct_top\" : [\"mouth_center_top_lip_x\", \"mouth_center_top_lip_y\"],\n",
    "    \"mouth_ct_bottom\" : [\"mouth_center_bottom_lip_x\", \"mouth_center_bottom_lip_y\"]\n",
    "}\n",
    "cols_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Traing Data - for keypoint sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_sep = [0 for i in cols_dict.keys()]\n",
    "train_labels_sep = [0 for i in cols_dict.keys()]\n",
    "for i, key in enumerate(cols_dict.keys()):\n",
    "    train_data_sep[i], train_labels_sep[i] = helper.subset_data(train_data,\n",
    "                                                                train_labels,\n",
    "                                                                full_keypoints,\n",
    "                                                                cols_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Dev Data - for keypoint sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_data_sep = [0 for i in cols_dict.keys()]\n",
    "dev_labels_sep = [0 for i in cols_dict.keys()]\n",
    "for i, key in enumerate(cols_dict.keys()):\n",
    "    dev_data_sep[i], dev_labels_sep[i] = helper.subset_data(dev_data,\n",
    "                                                                dev_labels,\n",
    "                                                                full_keypoints,\n",
    "                                                                cols_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye  Center Prediction\n",
    "\n",
    "- eye_ct_data\n",
    "- eye_ct_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses = train_labels_sep[0][1].size\n",
    "\n",
    "## Create cnn model for detecting eye center\n",
    "eye_ct_cnn = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                   featureMapLayers = [32,64,128,256,512],\n",
    "                                   numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                   imageWidth = 96, poolingSize = 2,\n",
    "                                   train_dropout_rate = [0.2,0.5])\n",
    "\n",
    "train_data_sep[0] = helper.load_2d_images(train_data_sep[0], 96)\n",
    "dev_data_sep[0] = helper.load_2d_images(dev_data_sep[0], 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6028, 1, 96, 96)\n",
      "(1005, 1, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "## Check if the reshape works\n",
    "print(train_data_sep[0].shape)\n",
    "print(dev_data_sep[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 / 3\n",
      "training time: 511.979686499 s, ----- loss: 0.187469573096 , RMSE: 20.7829231922\n",
      "validation loss: 0.194138256098 , val RMSE: 21.1493390452\n",
      "\n",
      "Epoch: 2 / 3\n",
      "training time: 514.298957825 s, ----- loss: 0.187469525536 , RMSE: 20.7829205559\n",
      "validation loss: 0.194138255486 , val RMSE: 21.1493390119\n",
      "\n",
      "Epoch: 3 / 3\n",
      "training time: 513.109895229 s, ----- loss: 0.187469515107 , RMSE: 20.7829199779\n",
      "validation loss: 0.194138254874 , val RMSE: 21.1493389786\n"
     ]
    }
   ],
   "source": [
    "eye_ct_train_result, eye_ct_val_result = eye_ct_cnn.SGD(train_data_sep[0],\n",
    "                                                        train_labels_sep[0],\n",
    "                                                        update_rule=\"backprop\",\n",
    "                                                        epochs = 3,\n",
    "                                                        miniBatchSize = 100,\n",
    "                                                        learning_rate = 0.01,\n",
    "                                                        validation = [dev_data_sep[0],\n",
    "                                                                     dev_labels_sep[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in range(len(eye_ct_cnn.params)):\n",
    "    filename = \"eye_ct_layer\" + str(layer+1)\n",
    "    helper.save_layer_params(eye_ct_cnn.params[layer], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.00562944,  0.00351338,  0.00451219, ..., -0.01202873,\n",
       "         0.00384001,  0.01784347],\n",
       "       [ 0.00448881,  0.01135894,  0.00970947, ...,  0.00451705,\n",
       "        -0.00257718,  0.00960052],\n",
       "       [ 0.00089288,  0.01375832, -0.00828643, ..., -0.00351875,\n",
       "        -0.02569854,  0.00482828],\n",
       "       ..., \n",
       "       [-0.00151452,  0.00098542,  0.01707603, ..., -0.00172229,\n",
       "        -0.00028029, -0.00657524],\n",
       "       [-0.00033551,  0.0088803 , -0.00600585, ...,  0.00037901,\n",
       "         0.00261588,  0.02065537],\n",
       "       [ 0.00345786,  0.00523346,  0.00523521, ..., -0.00113153,\n",
       "        -0.00822592, -0.00254993]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.load_saved_params(\"eye_ct_layer9_weights\").get_value()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZIAAAEKCAYAAAA4t9PUAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nrkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fa5c967cef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def plot_performance(train_result, validation_result):\n",
    "    plt.plot(train_result[:,1], linewidth=3, label=\"train\")\n",
    "    plt.plot(validation_result[:,0], linewidth=3, label=\"validation\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    #plt.ylim(1e-4, 1e-2)\n",
    "    #plt.yscale('log')\n",
    "    plt.show()\n",
    "\n",
    "plot_performance(eye_ct_train_result, eye_ct_val_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Eye center -- Try again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 1 / 25\n",
      "training time: 492.242276907 s, ----- loss: nan , RMSE: nan\n",
      "validation loss: nan , val RMSE: nan\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-1422b6153d66>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                         \u001b[0mlearning_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.03\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m                                                         validation = [dev_data_sep[0],\n\u001b[0;32m----> 8\u001b[0;31m                                                                       dev_labels_sep[0]])\n\u001b[0m",
      "\u001b[0;32m/home/ec2-user/repo/models/facial_keypoints/conv_net_helper.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, X, Y, update_rule, epochs, miniBatchSize, learning_rate, validation)\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mepochStartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatchStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchEnd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 251\u001b[0;31m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchStart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchStart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    252\u001b[0m             \u001b[0mtrain_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m             \u001b[0mtrain_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcost\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m48\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "eye_ct_train_result, eye_ct_val_result = eye_ct_cnn.SGD(train_data_sep[0],\n",
    "                                                        train_labels_sep[0],\n",
    "                                                        update_rule=\"rmsprop\",\n",
    "                                                        epochs = 25,\n",
    "                                                        miniBatchSize = 100,\n",
    "                                                        learning_rate = 0.03,\n",
    "                                                        validation = [dev_data_sep[0],\n",
    "                                                                      dev_labels_sep[0]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch      Cost        RMSE         Epoch Training Time(secs)\n",
      "-----      ----        -----        -------------------------\n",
      "  1.0     0.194379041536     21.1624505126     495.303448677\n",
      "  2.0     0.194379190295     21.1624586105     495.125259876\n",
      "  3.0     0.194378866151     21.1624409654     495.635089636\n",
      "  4.0     0.194378344606     21.1624125745     496.724184036\n",
      "  5.0     0.194378430017     21.1624172239     494.231838226\n",
      "  6.0     0.194379347633     21.1624671753     496.972456932\n",
      "  7.0     0.194378651167     21.1624292625     495.601482391\n",
      "  8.0     0.194378989827     21.1624476978     498.575871706\n",
      "  9.0     0.194378450807     21.1624183556     498.194295883\n",
      "  10.0     0.194378764091     21.1624354096     504.651228428\n"
     ]
    }
   ],
   "source": [
    "print(\"Epoch      Cost        RMSE         Epoch Training Time(secs)\")\n",
    "print(\"-----      ----        -----        -------------------------\")\n",
    "for i in range(len(train_result)):\n",
    "    print(\" \", train_result[i,0], \"   \", train_result[i,1],\n",
    "         \"   \", train_result[i,2], \"   \", train_result[i,3])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eye  Corner Prediction\n",
    "\n",
    "- eye_cr_data\n",
    "- eye_cr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses = train_labels_sep[1][1].size\n",
    "\n",
    "## Create cnn model for detecting eye center\n",
    "eye_cr_cnn = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                   featureMapLayers = [32,64,128,256,512],\n",
    "                                   numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                   imageWidth = 96, poolingSize = 2,\n",
    "                                   train_dropout_rate = [0.2,0.5])\n",
    "\n",
    "train_data_sep[1] = helper.load_2d_images(train_data_sep[1], 96)\n",
    "dev_data_sep[1] = helper.load_2d_images(dev_data_sep[1], 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eye_cr_train_result, eye_cr_val_result = eye_cr_cnn.SGD(train_data_sep[1],\n",
    "                                                        train_labels_sep[1],\n",
    "                                                        update_rule=\"rmsprop\",\n",
    "                                                        epochs = 30,\n",
    "                                                        miniBatchSize = 100,\n",
    "                                                        learning_rate = 0.03,\n",
    "                                                        validation = [dev_data_sep[1],\n",
    "                                                                     dev_labels_sep[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eyebrow Prediction\n",
    "\n",
    "- eyebrow_data\n",
    "- eyebrow_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses = train_labels_sep[2][1].size\n",
    "\n",
    "## Create cnn model for detecting eye center\n",
    "eyebrow_cnn = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                   featureMapLayers = [32,64,128,256,512],\n",
    "                                   numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                   imageWidth = 96, poolingSize = 2,\n",
    "                                   train_dropout_rate = [0.2,0.5])\n",
    "\n",
    "train_data_sep[2] = helper.load_2d_images(train_data_sep[2], 96)\n",
    "dev_data_sep[2] = helper.load_2d_images(dev_data_sep[2], 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eyebrow_train_result, eyebrow_val_result = eyebrow_cnn.SGD(train_data_sep[2],\n",
    "                                                        train_labels_sep[2],\n",
    "                                                        update_rule=\"rmsprop\",\n",
    "                                                        epochs = 30,\n",
    "                                                        miniBatchSize = 100,\n",
    "                                                        learning_rate = 0.03,\n",
    "                                                        validation = [dev_data_sep[2],\n",
    "                                                                     dev_labels_sep[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nose Prediction\n",
    "\n",
    "- nose_data\n",
    "- nose_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses = train_labels_sep[3][1].size\n",
    "\n",
    "## Create cnn model for detecting eye center\n",
    "nose_cnn = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                   featureMapLayers = [32,64,128,256,512],\n",
    "                                   numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                   imageWidth = 96, poolingSize = 2,\n",
    "                                   train_dropout_rate = [0.2,0.5])\n",
    "\n",
    "train_data_sep[3] = helper.load_2d_images(train_data_sep[3], 96)\n",
    "dev_data_sep[3] = helper.load_2d_images(dev_data_sep[3], 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nose_train_result, nose_val_result = nose_cnn.SGD(train_data_sep[3],\n",
    "                                                  train_labels_sep[3],\n",
    "                                                  update_rule=\"rmsprop\",\n",
    "                                                  epochs = 30,\n",
    "                                                  miniBatchSize = 100,\n",
    "                                                  learning_rate = 0.03,\n",
    "                                                  validation = [dev_data_sep[3],\n",
    "                                                                dev_labels_sep[3]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouth Corner Prediction\n",
    "\n",
    "- mouth_cr_data\n",
    "- mouth_cr_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses = train_labels_sep[4][1].size\n",
    "\n",
    "## Create cnn model for detecting eye center\n",
    "mouse_cr_cnn = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                     featureMapLayers = [32,64,128,256,512],\n",
    "                                     numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                     imageWidth = 96, poolingSize = 2,\n",
    "                                     train_dropout_rate = [0.2,0.5])\n",
    "\n",
    "train_data_sep[4] = helper.load_2d_images(train_data_sep[4], 96)\n",
    "dev_data_sep[4] = helper.load_2d_images(dev_data_sep[4], 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mouse_cr_train_result, mouse_cr_val_result = mouse_cr_cnn.SGD(train_data_sep[4],\n",
    "                                                          train_labels_sep[4],\n",
    "                                                          update_rule=\"rmsprop\",\n",
    "                                                          epochs = 30,\n",
    "                                                          miniBatchSize = 100,\n",
    "                                                          learning_rate = 0.03,\n",
    "                                                          validation = [dev_data_sep[4],\n",
    "                                                                        dev_labels_sep[4]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouth Center Top Prediction\n",
    "\n",
    "- mouth_ct_top_data\n",
    "- mouth_ct_top_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses = train_labels_sep[5][1].size\n",
    "\n",
    "## Create cnn model for detecting eye center\n",
    "mouse_ct_top_cnn = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                     featureMapLayers = [32,64,128,256,512],\n",
    "                                     numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                     imageWidth = 96, poolingSize = 2,\n",
    "                                     train_dropout_rate = [0.2,0.5])\n",
    "\n",
    "train_data_sep[5] = helper.load_2d_images(train_data_sep[5], 96)\n",
    "dev_data_sep[5] = helper.load_2d_images(dev_data_sep[5], 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mouse_ct_top_train_result, mouse_ct_top_val_result = mouse_ct_top_cnn.SGD(train_data_sep[5],\n",
    "                                                          train_labels_sep[5],\n",
    "                                                          update_rule=\"rmsprop\",\n",
    "                                                          epochs = 30,\n",
    "                                                          miniBatchSize = 100,\n",
    "                                                          learning_rate = 0.03,\n",
    "                                                          validation = [dev_data_sep[5],\n",
    "                                                                        dev_labels_sep[5]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mouth Center Bottom Prediction\n",
    "\n",
    "- mouth_ct_bottom_data\n",
    "- mouth_ct_bottom_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numClasses = train_labels_sep[6][1].size\n",
    "\n",
    "## Create cnn model for detecting eye center\n",
    "mouse_ct_bottom_cnn = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                     featureMapLayers = [32,64,128,256,512],\n",
    "                                     numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                     imageWidth = 96, poolingSize = 2,\n",
    "                                     train_dropout_rate = [0.2,0.5])\n",
    "\n",
    "train_data_sep[6] = helper.load_2d_images(train_data_sep[6], 96)\n",
    "dev_data_sep[6] = helper.load_2d_images(dev_data_sep[6], 96)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mouse_ct_bottom_train_result, mouse_ct_bottom_val_result = mouse_ct_bottom_cnn.SGD(train_data_sep[6],\n",
    "                                                          train_labels_sep[6],\n",
    "                                                          update_rule=\"rmsprop\",\n",
    "                                                          epochs = 30,\n",
    "                                                          miniBatchSize = 100,\n",
    "                                                          learning_rate = 0.03,\n",
    "                                                          validation = [dev_data_sep[6],\n",
    "                                                                        dev_labels_sep[6]])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
