{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained General 5 Layer CNN with Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:556: UserWarning: Theano flag device=gpu* (old gpu back-end) only support floatX=float32. You have floatX=float64. Use the new gpu back-end with device=cuda* for that value of floatX.\n",
      "  warnings.warn(msg)\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 5103)\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Device: gpu\n",
      "- Float float64\n",
      "- System Version: 3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n",
      "b'Hello, TensorFlow!'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from six.moves import cPickle\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "## Theano\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.pool import pool_2d\n",
    "\n",
    "## Keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input\n",
    "from keras.layers import Dropout, Flatten, Merge\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.initializers import glorot_uniform, he_uniform\n",
    "from keras.utils import plot_model\n",
    "from keras.callbacks import LearningRateScheduler, EarlyStopping, ReduceLROnPlateau, Callback\n",
    "\n",
    "from collections import OrderedDict\n",
    "import conv_net_helper as helper\n",
    "\n",
    "import pydot\n",
    "import h5py\n",
    "\n",
    "print(\"- Device:\", theano.config.device)\n",
    "print(\"- Float\", theano.config.floatX)\n",
    "print(\"- System Version:\", sys.version)\n",
    "import tensorflow as tf\n",
    "sess = tf.Session(config=tf.ConfigProto(log_device_placement=True))\n",
    "hello = tf.constant(\"Hello, TensorFlow!\")\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Loading data Done\n"
     ]
    }
   ],
   "source": [
    "X, Y = helper.load2d()\n",
    "train_data, dev_data, train_labels, dev_labels = helper.get_split_data(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1712, 1, 96, 96)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_model_performance(data):\n",
    "    plt.plot(data.history['loss'], linewidth=3, label='train')\n",
    "    plt.plot(data.history['val_loss'], linewidth=3, label='validation')\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.xlabel('epoch')\n",
    "    plt.ylabel('loss')\n",
    "    #plt.ylim(1e-4, 1e-2)\n",
    "    plt.yscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def execute_pretrain_model(epochs, train_data, train_labels, dev_data, dev_labels):\n",
    "    start = 0.03\n",
    "    stop = 0.001\n",
    "    batch_size = 128\n",
    "    \n",
    "    #X, y = helper.load2d()\n",
    "    #train_data, dev_data, train_labels, dev_labels = helper.get_split_data(X,y)\n",
    "    \n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3, 3), padding='valid', activation='relu', data_format = 'channels_first', input_shape=(1,96, 96)))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first'))\n",
    "    model.add(Dropout(np.cast['float32'](0.1)))  \n",
    "\n",
    "    model.add(Conv2D(64, (2, 2), padding='valid', activation='relu',data_format = 'channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first'))\n",
    "    model.add(Dropout(np.cast['float32'](0.2))) \n",
    "\n",
    "    model.add(Conv2D(128, (2, 2), padding='valid', activation='relu',data_format = 'channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first'))\n",
    "    model.add(Dropout(np.cast['float32'](0.3)))  \n",
    "    \n",
    "    model.add(Conv2D(256, (2, 2), padding='valid', activation='relu',data_format = 'channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2), data_format = 'channels_first'))\n",
    "    model.add(Dropout(np.cast['float32'](0.3))) \n",
    "    \n",
    "    model.add(Conv2D(512, (2, 2), padding='valid', activation='relu',data_format = 'channels_first'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2),data_format = 'channels_first'))\n",
    "    model.add(Dropout(np.cast['float32'](0.3)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dropout(np.cast['float32'](0.4))) \n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dropout(np.cast['float32'](0.4))) \n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dropout(np.cast['float32'](0.4))) \n",
    "    model.add(Dense(600, activation='relu'))\n",
    "    model.add(Dense(30))\n",
    "\n",
    "    sgd = SGD(lr=np.cast['float32'](0.01) , momentum=0.9, nesterov=True)\n",
    "    model.compile(loss='mean_squared_error', optimizer=sgd)\n",
    "    \n",
    "    early_stop = EarlyStopping(patience=100)\n",
    "    learning_rates = np.linspace(start, stop, epochs)\n",
    "    change_lr = LearningRateScheduler(lambda epoch: float(learning_rates[epoch]))\n",
    "    \n",
    "    data =  model.fit(train_data, train_labels, \n",
    "                       batch_size = batch_size,\n",
    "                       epochs=epochs, \n",
    "                       validation_data=(dev_data, dev_labels),\n",
    "                       callbacks=[change_lr, early_stop])\n",
    "    \n",
    "    \n",
    "    plot_model_performance(data)\n",
    "    #helper.get_error(model,dev_data, dev_labels)\n",
    "    #helper.save_model(model,\"pretrain_model\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1712 samples, validate on 428 samples\n",
      "Epoch 1/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.1155 - val_loss: 0.0660\n",
      "Epoch 2/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0224 - val_loss: 0.0232\n",
      "Epoch 3/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0086 - val_loss: 0.0141\n",
      "Epoch 4/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0068 - val_loss: 0.0104\n",
      "Epoch 5/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0061 - val_loss: 0.0084\n",
      "Epoch 6/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0057 - val_loss: 0.0072\n",
      "Epoch 7/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0056 - val_loss: 0.0065\n",
      "Epoch 8/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0054 - val_loss: 0.0060\n",
      "Epoch 9/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0053 - val_loss: 0.0055\n",
      "Epoch 10/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0052 - val_loss: 0.0052\n",
      "Epoch 11/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0051 - val_loss: 0.0050\n",
      "Epoch 12/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0051 - val_loss: 0.0049\n",
      "Epoch 13/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0050 - val_loss: 0.0048\n",
      "Epoch 14/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0050 - val_loss: 0.0047\n",
      "Epoch 15/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 16/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0049 - val_loss: 0.0046\n",
      "Epoch 17/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 18/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0049 - val_loss: 0.0045\n",
      "Epoch 19/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 20/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 21/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 22/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 23/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0048 - val_loss: 0.0044\n",
      "Epoch 24/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 25/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0044\n",
      "Epoch 26/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 27/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 28/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 29/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 30/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 31/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 32/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 33/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 34/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 35/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 36/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 37/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 38/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 39/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 40/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 41/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 42/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 43/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 44/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 45/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 46/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 47/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 48/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 49/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 50/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 51/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 52/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 53/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 54/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 55/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 56/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 57/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 58/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 59/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 60/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 61/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 62/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 63/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 64/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0046 - val_loss: 0.0043\n",
      "Epoch 65/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 66/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 67/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 68/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 69/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 70/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 71/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 72/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 73/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 74/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 75/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 76/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 77/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 78/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 79/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 80/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 81/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 82/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 83/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 84/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 85/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 86/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 87/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 88/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 89/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 90/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 91/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 92/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 93/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 94/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 95/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 96/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 97/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 98/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 99/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 100/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 101/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 102/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 103/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 104/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 105/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 106/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 107/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 108/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 109/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 110/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 111/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 112/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 113/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 114/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 115/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 116/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 117/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 118/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 119/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 120/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 121/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 122/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 123/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 124/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 125/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 126/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 127/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 128/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 129/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 130/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 131/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 132/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 133/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 134/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 135/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 136/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 137/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 138/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 139/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 140/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 141/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 142/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 143/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 144/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 145/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 146/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 147/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 148/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 149/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 150/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 151/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 152/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 153/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 154/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 155/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 156/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 157/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 158/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 159/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 160/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 161/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 162/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 163/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 164/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 165/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 166/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 167/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 168/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 169/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 170/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 171/500\n",
      "1712/1712 [==============================] - 74s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 172/500\n",
      "1712/1712 [==============================] - 79s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 173/500\n",
      "1712/1712 [==============================] - 77s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 174/500\n",
      "1712/1712 [==============================] - 78s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 175/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 176/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 177/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 178/500\n",
      "1712/1712 [==============================] - 144s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 179/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 180/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 181/500\n",
      "1712/1712 [==============================] - 144s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 182/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 183/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 184/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 185/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 186/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 187/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 188/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 189/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 190/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 191/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 192/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 193/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 194/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 195/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 196/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 197/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 198/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 199/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 200/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 201/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 202/500\n",
      "1712/1712 [==============================] - 145s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 203/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 204/500\n",
      "1712/1712 [==============================] - 144s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 205/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 206/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 207/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 208/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 209/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 210/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 211/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 212/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 213/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 214/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 215/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 216/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 217/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 218/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 219/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 220/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 221/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 222/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 223/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 224/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 225/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 226/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 227/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 228/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 229/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 230/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 231/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 232/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 233/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 234/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 235/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 236/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 237/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 238/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 239/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 240/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 241/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 242/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 243/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 244/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 245/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 246/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 247/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 248/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 249/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 250/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 251/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 252/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 253/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 254/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 255/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 256/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 257/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 258/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 259/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 260/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 261/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 262/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 263/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 264/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 265/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 266/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 267/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 268/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 269/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 270/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 271/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 272/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 273/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 274/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 275/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 276/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 277/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 278/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 279/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 280/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 281/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 282/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 283/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 284/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 285/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 286/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 287/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 288/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 289/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 290/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 291/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 292/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 293/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 294/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 295/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 296/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 297/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 298/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 299/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 300/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 301/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 302/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 303/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0045 - val_loss: 0.0043\n",
      "Epoch 304/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 305/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 306/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 307/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 308/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 309/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 310/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 311/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 312/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 313/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 314/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 315/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 316/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 317/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 318/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 319/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 320/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 321/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 322/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 323/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 324/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 325/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 326/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 327/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 328/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 329/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 330/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 331/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 332/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 333/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 334/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 335/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 336/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 337/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 338/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 339/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 340/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 341/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 342/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 343/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 344/500\n",
      "1712/1712 [==============================] - 144s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 345/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 346/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 347/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 348/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 349/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 350/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 351/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 352/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 353/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 354/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 355/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 356/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 357/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 358/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 359/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 360/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 361/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 362/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 363/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 364/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 365/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 366/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 367/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 368/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 369/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 370/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 371/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 372/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 373/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 374/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 375/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 376/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 377/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 378/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 379/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 380/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 381/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 382/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 383/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 384/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 385/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 386/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 387/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 388/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 389/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 390/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 391/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 392/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 393/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 394/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 395/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 396/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 397/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 398/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 399/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 400/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 401/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 402/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 403/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 404/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 405/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 406/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 407/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 408/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 409/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 410/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 411/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 412/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 413/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 414/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 415/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 416/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 417/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 418/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 419/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 420/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 421/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 422/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 423/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 424/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 425/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 426/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 427/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 428/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 429/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 430/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 431/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 432/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 433/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 434/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 435/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 436/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 437/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 438/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 439/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 440/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 441/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 442/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 443/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 444/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 445/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 446/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 447/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 448/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 449/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 450/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 451/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 452/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 453/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 454/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 455/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 456/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 457/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 458/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 459/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 460/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 461/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 462/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 463/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 464/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 465/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 466/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 467/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 468/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 469/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 470/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 471/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 472/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 473/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 474/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 475/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 476/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 477/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 478/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 479/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 480/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 481/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 482/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 483/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 484/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 485/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 486/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 487/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 488/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 489/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 490/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 491/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 492/500\n",
      "1712/1712 [==============================] - 143s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 493/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 494/500\n",
      "1712/1712 [==============================] - 141s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 495/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 496/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 497/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 498/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 499/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n",
      "Epoch 500/500\n",
      "1712/1712 [==============================] - 142s - loss: 0.0044 - val_loss: 0.0043\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEKCAYAAAAFJbKyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X2UXHWd5/H3996qfkyn00kg5AFNGBgSCIGEiDiABFE2\nPAkoCrPiMYjmDOP4MKO7G3VmdfboyKweZD3iAyKiDqAsTBZUWAQnDbgqJEGICQnkgWBCyCOk053u\n6q6q+9s/7q3u252qpKq7q6tS+bzO6dO3bt+H36/S6U/9fr97f9ecc4iIiBTLq3QBRETk6KLgEBGR\nkig4RESkJAoOEREpiYJDRERKouAQEZGSKDhERKQkCg4RESmJgkNEREqSqHQBymHy5Mlu5syZw9r3\n4MGDNDc3j26BqpzqfGxQnY8Nw63z6tWr9zrnjitm25oMjpkzZ7Jq1aph7dve3s6iRYtGt0BVTnU+\nNqjOx4bh1tnMXi12W3VViYhISRQcIiJSEgWHiIiUpCbHOESkdqTTabZv304qlSp539bWVtavX1+G\nUlWvI9W5oaGBGTNmkEwmh30OBYeIVLXt27fT0tLCzJkzMbOS9u3s7KSlpaVMJatOh6uzc459+/ax\nfft2Zs2aNexzqKtKRKpaKpVi0qRJJYeGHMrMmDRp0rBab3FqcUS27Oli54EUL+7LcmpHD1NbGytd\nJBGJKDRGz2i8lwqOyA+efoX7nv0zAOOn7+aGc99a4RKJiFQndVVFvFgI6znsIpKzf/9+vvOd75S8\n32WXXcb+/fvLUKLKU3BEvFjzTbEhIjmFgiOTyRx2v0ceeYQJEyaUq1gVpa6qSLzbLwgUHSISWrZs\nGZs3b+ass84imUzS0NBAW1sbGzZs4OWXX+bqq69m27ZtpFIpPv3pT7N06VJgYOqjrq4uLr30Us4/\n/3x+97vfMX36dB566CEaG4/ecVQFR0QtDpHqN3PZr8p27K23XJ53/S233MLatWt5/vnnaW9v5/LL\nL2ft2rX9l7PeddddTJw4kZ6eHt72trfx/ve/n0mTJg06xsaNG7nvvvv4wQ9+wAc/+EEefPBBbrjh\nhrLVpdwUHHmowSEihZxzzjmD7oH41re+xfLlywHYtm0bGzduPCQ4Zs2axVlnnQXA2WefzdatW8es\nvOVQ9cFhZicBXwRanXPXlus8g1ocGhwXkQLiU5a3t7fzxBNP8Pvf/56mpiYWLVqU9x6J+vr6/mXf\n9+np6RmTspZLWYPDzO4CrgB2O+fmxtYvBv4X4AN3OuduKXQM59wW4CYze6CcZR18VVU5zyQiw1Wo\nO6mQ0bhzvKWlhc7Ozrw/6+jooK2tjaamJjZs2MAf/vCHEZ3raFHuFsfdwLeBn+RWmJkP3A68B9gO\nrDSzhwlD5GtD9v+oc253mcsYlWtgOVByiEhk0qRJnHfeecydO5fGxkamTJnS/7PFixfzve99jzlz\n5nDqqady7rnnVrCkY6esweGce8rMZg5ZfQ6wKWpJYGY/A65yzn2NsHVSERocF5FC7r333rzr6+vr\nefTRR/P+LDeOMXnyZNauXdu//nOf+9yol2+sVWKMYzqwLfZ6O/D2Qhub2STgq8B8M/t8FDD5tlsK\nLAWYMmUK7e3tJRVq27a+/uVNmzfT7rYdZuva0tXVVfL7dbRTnY8era2tBbuKjiSbzQ5736NVMXVO\npVIj+l2o+sFx59w+4G+K2O4O4A6AhQsXulIfnfhMagO8shmAWbNOYtGik0su69FKj9c8NhytdV6/\nfv2wxyk0O25+DQ0NzJ8/f9jnqMSd468BJ8Zez4jWVVR82i9dVSUiUlglgmMlcIqZzTKzOuB64OEK\nlGOQ+BiH7uMQESmsrMFhZvcBvwdONbPtZnaTcy4D/B3wGLAeuN85t66c5SiGLscVESlOua+q+usC\n6x8BHinnuUs2qMWh5BARKaSmZsc1syvN7I6Ojo6S9x3U4hjFMonIsWXcuHEA7Nixg2uvzT/ZxaJF\ni1i1atVhj3PbbbfR3d3d/7qapmmvqeBwzv3CObe0tbW15H0NTTkiIqNn2rRpPPDA8Ce8GBoc1TRN\ne00Fx0hojENE8lm2bBm33357/+svf/nLfOUrX+Hiiy9mwYIFnHHGGTz00EOH7Ld161bmzg1nWurp\n6eH6669nzpw5XHPNNYPmqrr55ptZuHAhp59+Ol/60peAcOLEHTt2cNFFF3HRRRcB4TTte/fuBeDW\nW29l7ty5zJ07l9tuu63/fHPmzOGTn/wkp59+OpdccknZ5sSq+vs4xornaYxDpOp9ubTehJLu4Phy\n/i7u6667js985jN84hOfAOD+++/nscce41Of+hTjx49n7969nHvuubz3ve8t+Dzv7373uzQ1NbF+\n/XrWrFnDggUL+n/21a9+lYkTJ5LNZrn44otZs2YNn/rUp7j11ltZsWIFkydPHnSs1atX86Mf/Yhn\nnnkG5xxvf/vbufDCC2lra2Pjxo3ceeed3H333WWdvl0tjjx0Oa6I5MyfP5/du3ezY8cOXnjhBdra\n2jjhhBP4whe+wLx583j3u9/Na6+9xq5duwoe46mnnur/Az5v3jzmzZvX/7P777+fBQsWMH/+fNat\nW8eLL7542PL89re/5ZprrqG5uZlx48bxvve9j6effhoIp2/PHbuc07erxREZPFeVkkNEBnzgAx/g\ngQceYOfOnVx33XXcc8897Nmzh9WrV5NMJpk5c2be6dSP5JVXXuEb3/gGK1eupK2tjSVLlgzrODlj\nNX27giNiGuMQqX4FupMKGa0pR6677jo+/vGPs3fvXp588knuv/9+jj/+eJLJJCtWrODVV1897P7v\nfOc7uffee3nXu97F2rVrWbNmDQAHDhygubmZ1tZWdu3axaOPPto/LUxuOvehXVUXXHABS5YsYdmy\nZTjnWL58OT/96U9HXMdS1FRwmNmVwJUnn1z6PFODB8eVHCIy4PTTT6ezs5Pp06czdepUPvShD3Hl\nlVdyxhlnsHDhQmbPnn3Y/W+++WZuvPFG5syZw5w5czj77LMBOPPMM5k/fz6zZ8/mxBNP5Lzzzuvf\nZ+nSpSxevJhp06axYsWK/vULFixgyZIlnHPOOQB87GMfY/78+WP6VEGrxT+SCxcudEe6RnqoHzy1\nha8+sh6Am86fxT9dcVo5ilaVjtbJ70ZCdT56rF+/njlz5gxrX01ymF++99TMVjvnFhZzDg2OR/Qg\nJxGR4ig4IoOfOV7BgoiIVDkFR8Q0xiFStfR/cvSMxnup4Ijo0bEi1amhoYF9+/YpPEaBc459+/bR\n0NAwouPU1FVVI6ExDpHqNGPGDLZv386ePXtK3jeVSo34j+TR5kh1bmhoYMaMGSM6h4IjYhrjEKlK\nyWSSWbNmDWvf9vb2ET0i9Wg0FnWuqa6q0ZpWXVOOiIgUVlPBoWnVRUTKT11VkTmv3M3P636FT8C6\njiXAvCPtIiJyTFJwRMZ3v8pfeBsAeDW9r8KlERGpXjXVVTUSzvz+ZSOoYElERKqbgqNf7K1w2coV\nQ0Skyik4crxYi0OD4yIiBSk4cmL3cZhaHCIiBSk4IvExDpzGOERECqmp4BjJDYDYwFthCg4RkYJq\nKjhGcgNgfIwDXVUlIlJQTQXHiMRaHJ5aHCIiBSk4cjTGISJSFAVHjq6qEhEpioIjZ1CLQ/dxiIgU\nouDI8eJXVanFISJSiIIjJ9bi8HRVlYhIQQqOHIvPVaXgEBEpRMGR4+kGQBGRYig4cjStuohIUWoq\nODTliIhI+dVUcIzomePxO8fV4hARKaimgmNEPN05LiJSDAVHjuaqEhEpioIjR7PjiogURcGRo8Fx\nEZGiKDgiFmtxeJqrSkSkIAVHTrzFgeaqEhEpRMERibc4DLU4REQKUXDkmGbHFREphoIjJ97i0BiH\niEhBCo7I4DvH1eIQESlEwZFjanGIiBRDwRExTy0OEZFi1FRwjGh2XE/PHBcRKUZNBYdmxxURKb+a\nCo6RGHwfh4JDRKQQBUeOp9lxRUSKoeCI6M5xEZHiKDgiuo9DRKQ4Co4cL9G/qBaHiEhhCo4cs/5F\njXGIiBSm4Ih4g1ocCg4RkUIUHJHBd44rOEREClFw5GiuKhGRoig4ImpxiIgUR8GRE3/muIJDRKQg\nBUfEU4tDRKQoCo6Ixa+q0uW4IiIFKTgiGuMQESmOgiNig8Y4dFWViEghNRUcI3qQk57HISJSlJoK\njpE8yMnT7LgiIkWpqeAYkVhw+JodV0SkIAVHJH45rlocIiKFKTgiphsARUSKouCIDAoOzVUlIlKQ\ngiOiFoeISHEUHBEzBYeISDEUHBHNVSUiUhwFR2TwlCMa4xARKUTBETE/fh+HWhwiIoUUFRxm9mkz\nG2+hH5rZc2Z2SbkLN5Z057iISHGKbXF81Dl3ALgEaAM+DNxStlJVQHxwXC0OEZHCig0Oi75fBvzU\nObcutq4mxFscnjnQvRwiInkVGxyrzezXhMHxmJm1QG19LDfPCNxAFrpA81WJiOSTOPImANwEnAVs\ncc51m9lE4MbyFWvsmRkZPLxogkMXZDG/2LdHROTYUWyL4x3AS865/WZ2A/CPwDAeelHdMgx0V7ls\nuoIlERGpXsUGx3eBbjM7E/gssBn4SdlKVSHx4AgUHCIieRUbHBnnnAOuAr7tnLsdaClfsSojE+u5\ny6b7KlgSEZHqVWwnfqeZfZ7wMtwLzMwDkuUrVmWk1VUlInJExbY4rgN6Ce/n2AnMAL5etlJVSLzF\nEWTU4hARyaeo4IjC4h6g1cyuAFLOudoe41BwiIjkVeyUIx8EngU+AHwQeMbMri1nwSohY/EWh7qq\nRETyKXaM44vA25xzuwHM7DjgCeCBchWsEgZfjqsWh4hIPsWOcXi50IjsK2HfMWNmV5rZHR0dw7vF\nJBsf41BwiIjkVewf//9rZo+Z2RIzWwL8CnikfMUaHufcL5xzS1tbW4e1f7yrymUyo1UsEZGaUlRX\nlXPuv5jZ+4HzolV3OOeWl69YlRG/qkpdVSIi+RU9GZNz7kHgwTKWpeKy5pN7FIcGx0VE8jtscJhZ\nJ+R9qpEBzjk3viylqpDsoBaHgkNEJJ/DBodzruamFTmcbOxhTk73cYiI5FV1V0ZVUsYGZlFxgVoc\nIiL5KDhi4l1VqKtKRCQvBUfMoK4qBYeISF4Kjphg0H0cCg4RkXwUHDHxGwDVVSUikp+CI2ZQi0OD\n4yIieSk4YrKm+zhERI5EwRETqKtKROSIFBwx8eAwzVUlIpKXgiMmqxsARUSOSMERE3jxripNqy4i\nko+CI8bFu6rU4hARyUvBERO/qgoFh4hIXgqOmMFdVQoOEZF8FBwxzhsYHFdwiIjkp+CIiV9VpTEO\nEZH8FBwxWa++f9nL9lawJCIi1UvBEZOJB0cmVcGSiIhULwVHTNaPBUegFoeISD4KjpisV9e/7GXV\n4hARyUfBETN4jENzVYmI5KPgiMn6Df3LanGIiOSn4IgJYi0OX1dViYjkpeCIySZiwaHBcRGRvBQc\nMYHu4xAROSIFR0yQGBjjSKjFISKSl4IjZtAYR9AHzlWwNCIi1UnBEeN5Hr0uNtGh7h4XETmEgiPG\n9yCFgkNE5HAUHDGeZ/QycPc4aQWHiMhQCo4Y34yUuqpERA5LwRHj2ZAWh4JDROQQiSNvUllmdjVw\nOTAe+KFz7tflOpfn2eAxjnRPuU4lInLUKmuLw8zuMrPdZrZ2yPrFZvaSmW0ys2WHO4Zz7v845z4O\n/A1wXTnL66vFISJyROVucdwNfBv4SW6FmfnA7cB7gO3ASjN7GPCBrw3Z/6POud3R8j9G+5WNZ9Dt\nBu7loK+7nKcTETkqlTU4nHNPmdnMIavPATY557YAmNnPgKucc18Drhh6DDMz4BbgUefcc+Usr+cZ\nXTQOrOjrLOfpRESOSpUY45gObIu93g68/TDbfxJ4N9BqZic7576XbyMzWwosBZgyZQrt7e0lF+zV\nV/qYwsC0IxvWrGbnnraSj3O06erqGtb7dTRTnY8NqnN5VP3guHPuW8C3itjuDuAOgIULF7pFixaV\nfK6N3ha6tgwEx+xZM5h9bunHOdq0t7cznPfraKY6HxtU5/KoxOW4rwEnxl7PiNZVnBl0x1oc9HVV\nrjAiIlWqEsGxEjjFzGaZWR1wPfBwBcpxCN8zupyCQ0TkcMp9Oe59wO+BU81su5nd5JzLAH8HPAas\nB+53zq0rZzmK5Xs2uMXRq+AQERmq3FdV/XWB9Y8Aj5Tz3MPhmXFwUFfVwcoVRkSkStXUlCNmdqWZ\n3dHR0TGs/T0zDg7qqtLluCIiQ9VUcDjnfuGcW9ra2jqs/X0PDg66j0MtDhGRoWoqOEYqbHHE7hzX\nGIeIyCEUHDENSV8tDhGRI1BwxDTV+XTGg6P3QOUKIyJSpRQcMY11Pgdc88CKnv2VK4yISJVScMQ0\n1SXopJHAWbiirxOy6coWSkSkytRUcIz0ctymOh+HxwGaBlamhncsEZFaVVPBMdLLcRuTPgAd6q4S\nESmopoJjpJrqouAgFhwpBYeISJyCI6apLpyBRS0OEZHCFBwxDUkPQy0OEZHDUXDEmBl1PnS4cQMr\ne96sXIFERKqQgmOIeh/eJBYc3fsqVxgRkSqk4Biizjd2udhzxg/sqFxhRESqUE0Fx0jv44CwxTEo\nODp3jkLJRERqR00Fx0jv4wCo942dbuLAik61OERE4moqOEZDc3JoV9XrlSuMiEgVUnAM0Vpv7KWV\nbG6+qu69kOmtbKFERKqIgmOI1joji88eJgys1DiHiEg/BccQrfVhS2OnBshFRPJScAwxIQqOXRog\nFxHJS8ExRGt/cGiAXEQkHwXHEBPydlWpxSEiklNTwTEaNwBObjSSvg3uqtLd4yIi/WoqOEbjBkDf\nM2ZNbuY1Jg+sfPPVUSidiEhtqKngGC0nHz+OV4ITBla8sblyhRERqTIKjjxOmzqeXbTR4+rCFT1v\nQvcblS2UiEiVUHDkccW8aYCx1U0ZWPnGloqVR0Skmig48pg5uZkzZ7Sy1cW7qxQcIiKg4CjoglOO\nGxQcwd5NFSyNiEj1UHAUsHjuCYOCY8eWdRUsjYhI9VBwFDB3eiuzTzur/3Vq18s45ypYIhGR6qDg\nOIxL3nl+//Jb+jbz2R//B5lsUMESiYhUnoLjMKafOJNtTXMAqLMsTRt/wd/e8xw9fdkKl0xEpHJq\nKjhGY8qRoU44/yP9yxd5z/PrF3ex8CuP8y+PrGfXgdSonUdE5GhRU8ExGlOODJWcvbh/+R3eizSS\n4mBfljue2sIF/7qC21dsYsPOA6N2PhGRapeodAGq3sRZMOkU2LeRJuvlRv8xvpO9CoC+bMDXH3uJ\nrz/2Em+b2cbp01qZPK6OaxbMYFprA2ZW4cKLiIw+BUcx3vG38Mu/B+BzDct5vfVClu+YMGiTlVvf\nZOXWNwH4xq9fJuEZ4xoSTGttZNqERs5+axtzprZgZvhmnDJlHMe31CtcROSoo+AoxvwPw6ofwc41\neNk+vpn4Nlff8HPu++MednT0sGb7oWMqmcCxvzvN/u40L75+gCfW7zpkm/ENCaZNaGRvVx+96SxT\nWhuYMr6e06aOp6kuwRsH+3jLxCaa6xPs7epl5uRmWhoSOOcIApjQlOStk5rZ09nLgVSav5zSwhsH\n+2htTDKhKUkqncUzoy8T0NZcNxbvlIgcAxQcxfCT8P474fsXQqYHdr/Ihc//PRde+U2Y8Bae+/Ob\nPP3yXrrTGR5ft4stew8WddgDqQwHdnb2v+7c3cWm3V38v037ylKNxqRPbyZL4MLQOWF8A5v3dNHg\nOWa88DRJ32iuS+BFI1/1CZ/93X1MaKpjQmOSg30ZsoEjlQ44vqWe41rqCZyjLxOQ9D12d/bigAmN\nSdqaktQnfZK+4ZmR8IxM4NjZkWLiuDoaEj4O6OnLYGb09GXp6s0wZXwDb5nYRE86S+AcDUmfxug4\nuzt7SXjR8XyjuT789e1KZRjfmCTpGwd60tQnfOqTHtve6KapLkHS95g8ro6GpI/vhWXZeTDg1X0H\n6e7L4hx4HiQ8j75MQH3S442DffRlAnzPmNRcR9gwNBqSHql0wLj6BL2ZMJgD5+hMZTCD8Q1JzMJj\n5bYNnCOVznKwN0tLQ4KGpI/nQWtjEoA3D6bxPaOxzu+/Vyh3x5AB4+oTpLOOwDm6+7L4ntGbztJc\nn6CpzicbOLLOUeeH/3DOQdY5DEj4HtnA0dGT5mDa0dGdprUpWdLvTSYbEEQFSvp2xFZybyZLne9h\nZjjn6MsGJDwP3yutdR1EJ/WG7JcNXMnHOpaMxf1mVos3tS1cuNCtWrVqWPu2t7ezaNGi/D9c+UP4\n1T8MvPbr4Owb4ewl0DoDGsYDsGN/D7sOpOhMZdj2ZjePrdtFXyZLTzqI/rB5bH+zh67ezLDKKFKs\nuoQHLhyP61/ne2BhKJmBYdF3MBu87JyjqzfTHxwQhQcDf7g9D1Lp8PhmYXA1RiGdDRw96fDydd+z\n8MvC755B0vdI+h69mWx/KPpm+L7RlQr/f7Q115HLiZ6+LAdSGaa2NpDwB8oQL08811I9PTQ2NpLO\nOnZ3pmhrqusP+8C5/hCKn7cvE5BKB6SzAROb60h4Rldvlr5MlglNdQTO0ZsJ+oM6EwQ4B4EL/2g7\n6D+2AfVJn1RfFi/60JL7njtv0vfY353ur2PgoLneJ5N1pLMBjXU+fZkAz6z/XJnAkckG4ffAcdy4\negAO9KQ5abzjoc8OXNRTLDNb7ZxbWMy2anGUYuFHYd9m+MPt4etsHzz7/fALg2nz4eSLmdYylWnJ\nRmhsg6kT+dCJ9ZBshERD/3fnAnZ1HOTP3Q001SfozQT0prNs2tPF1r3dbHuzm75MwOsdPTQkfU6b\nOp7XO1Lhp7mEj2ewcVcXr+3v6S9eU52PEX5a7da9JgL0ZQ69YbVvhDexprOOgTYREPtVy30OzYVF\nXDYI/5iWak9n7yHrXu8o4VL47u7+xd15jnXYXft6Br0+kBrGh71h7LO3q7Tt438HDqbLf7GsgqMU\nZrD4X+DUS+E3/wzbV8Z+6GDHc+FXMYcCTgBO8BLhK/PAjL8yL1yOrSNoglcCSDZANg3pHkg24hp8\nghM8fM8Hzw+3d0H4iQfDS3fj6prptQZSWSOZSJLwfRK+R08mIJMNP6309hykpaWF3ug/ezLhYYR/\nILzoU6NzYVF8C7uKUpls9Ecg/PTmoL8LKZXOkom6VjzPx/M8LEjj8PATCdIu7D7xCHDO4RkEQUBn\nb0AymcDMwzPwLexyCaI/OInwgzKZwOH7Hmnnk3Y+Cd8nG2QJgoB6HwjCT2LmWdgNFfuk5hwEODKZ\nLI7wE6ZvXv8narPw+PUJP/pUGv7buqieuU9+jrAbiP79jHTW4XD4ZjiMbKw173lGne+RCXKfdCGT\ndWBh+QzI/Tk3LDqskXFGxoXrAgjLbOG5M1nX3yVlxqBWQe4DRP/5LfeJuKhfz0O4qIzD2d8s/H1k\nuOce3m6x/YffrTWyc4+sO2245d7fdzxw6YjOfSQKjuGYdQHc9Dhs+g08893w+3B/xYIiPo2k9h+6\nrif8tfTzbB5fb0Bj9BXXMnSn4oZlym+se+8KNcz6CqyP/18utG++X4WAgWTIyfePd7jzDT1HTd2F\nJaOlY9ypZT+HgmO4zOCUd4dfALvWwStPQ/c+2P/n8KmBmZ6wdZBORcux7wA4SHcXPIWISDVScIyW\nKaeHX6VwLux6woELwtcuGPw6yIbhYl74PVEPicYwgIJstF30FWSjbq7ouPXjwuDqO3jotjHPv/AC\nZ5155tDCFVf+I24T1cPzw2MG2aicRtgdZwOjmbn6xg26gie27AII0mE9XTDQVWfR99w2Ba4A+tPa\ntZwxd26eOuSp05G2GenP823jonGEQb8TI+k4cWzYsIHZs2cPY9eRdxYNf9eRnfull17i1FP/sgLn\nHuF7NoJzb9u6m9GbOyM/BUclmUGimPsrJpW1GPv/7OCkC8t6jmqzb2czzF5U6WKMqZ0d7cyev6jS\nxRhTr3e2c+rZiypdjDG192B72c+hXlIRESlJTQVHOWbHFRGRwWoqOMoxO66IiAxWU8EhIiLlp+AQ\nEZGSKDhERKQkCg4RESlJTc6Oa2Z7gFeHuftkYO8oFudooDofG1TnY8Nw6/xW59xxxWxYk8ExEma2\nqtiphWuF6nxsUJ2PDWNRZ3VViYhISRQcIiJSEgXHoe6odAEqQHU+NqjOx4ay11ljHCIiUhK1OERE\npCQKjoiZLTazl8xsk5ktq3R5RouZ3WVmu81sbWzdRDN73Mw2Rt/bYj/7fPQevGRm/6kypR4ZMzvR\nzFaY2Ytmts7MPh2tr9l6m1mDmT1rZi9Edf7naH3N1jnHzHwz+6OZ/TJ6XdN1NrOtZvYnM3vezFZF\n68a2zs65Y/6L8CGem4GTgDrgBeC0SpdrlOr2TmABsDa27n8Cy6LlZcC/RsunRXWvB2ZF74lf6ToM\no85TgQXRcgvwclS3mq034VOuxkXLSeAZ4NxarnOs7v8A3Av8Mnpd03UGtgKTh6wb0zqrxRE6B9jk\nnNvinOsDfgZcVeEyjQrn3FPAG0NWXwX8OFr+MXB1bP3PnHO9zrlXgE2E781RxTn3unPuuWi5E1gP\nTKeG6+1CXdHLZPTlqOE6A5jZDOBy4M7Y6pqucwFjWmcFR2g6sC32enu0rlZNcc69Hi3vBKZEyzX3\nPpjZTGA+4Sfwmq531GXzPLAbeNw5V/N1Bm4D/isQfx5yrdfZAU+Y2WozWxqtG9M669GxxzjnnDOz\nmry0zszGAQ8Cn3HOHbDY88drsd7OuSxwlplNAJab2dwhP6+pOpvZFcBu59xqM1uUb5taq3PkfOfc\na2Z2PPC4mW2I/3As6qwWR+g14MTY6xnRulq1y8ymAkTfd0fra+Z9MLMkYWjc45z792h1zdcbwDm3\nH1gBLKa263we8F4z20rYvfwuM/s3arvOOOdei77vBpYTdj2NaZ0VHKGVwClmNsvM6oDrgYcrXKZy\nehj4SLT8EeCh2PrrzazezGYBpwDPVqB8I2Jh0+KHwHrn3K2xH9Vsvc3suKilgZk1Au8BNlDDdXbO\nfd45N8NM6d8CAAACZElEQVQ5N5Pw/+x/OOduoIbrbGbNZtaSWwYuAdYy1nWu9BUC1fIFXEZ49c1m\n4IuVLs8o1us+4HUgTdi/eRMwCfgNsBF4ApgY2/6L0XvwEnBppcs/zDqfT9gPvAZ4Pvq6rJbrDcwD\n/hjVeS3w36P1NVvnIfVfxMBVVTVbZ8IrP1+Ivtbl/laNdZ1157iIiJREXVUiIlISBYeIiJREwSEi\nIiVRcIiISEkUHCIiUhIFh0gVMbNFuVleRaqVgkNEREqi4BAZBjO7IXr+xfNm9v1ogsEuM/tm9DyM\n35jZcdG2Z5nZH8xsjZktzz0rwcxONrMnomdoPGdmfxEdfpyZPWBmG8zsHotPsiVSBRQcIiUysznA\ndcB5zrmzgCzwIaAZWOWcOx14EvhStMtPgP/mnJsH/Cm2/h7gdufcmcBfEd7hD+Fsvp8hfJbCSYRz\nMolUDc2OK1K6i4GzgZVRY6CRcFK5APh5tM2/Af9uZq3ABOfck9H6HwP/O5pvaLpzbjmAcy4FEB3v\nWefc9uj188BM4Lflr5ZIcRQcIqUz4MfOuc8PWmn2T0O2G+58Pr2x5Sz6fypVRl1VIqX7DXBt9DyE\n3POe30r4/+naaJv/DPzWOdcBvGlmF0TrPww86cInE243s6ujY9SbWdOY1kJkmPRJRqREzrkXzewf\ngV+bmUc48/AngIPAOdHPdhOOg0A4zfX3omDYAtwYrf8w8H0z+x/RMT4whtUQGTbNjisySsysyzk3\nrtLlECk3dVWJiEhJ1OIQEZGSqMUhIiIlUXCIiEhJFBwiIlISBYeIiJREwSEiIiVRcIiISEn+PyUu\nKelp3x4XAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f07565076d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = execute_pretrain_model(500, train_data, train_labels, dev_data, dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def save_model(model, name):\n",
    "    json_string = model.to_json()\n",
    "    architecture = name+'_architecture.json' \n",
    "    weights = name+'_weights.h5'\n",
    "    open(architecture, 'w').write(json_string)\n",
    "    model.save_weights(weights)\n",
    "    \n",
    "save_model(model,\"Pretrain_Model_Try\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
