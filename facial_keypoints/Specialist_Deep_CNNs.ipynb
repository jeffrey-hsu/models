{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specialist Convolutional Neural Network Models\n",
    "\n",
    "In this notebook we build several CNN models each trained to predict different facial keypoint sets. The rationale for such approach is that each keypoint contains different number of label observations. Some images show face on the side, thus not all keypoints are revealed. In order to fully utilize labels, other than just examples where full set of keypoints are marked, keypoints close to each other and which number of observations are relatively close are trained with a CNN. This gives us several CNN models. The final prediction is done via all CNNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer (type)                  Output Shape              Param #          Param Shape       \n",
      "===========================================================================================\n",
      "conv2d_1 (Conv2D)             (None, 32, 96, 96)        800              (32, 1, 5, 5)     \n",
      "maxpooling2d_1 (Pooling)      (None, 32, 48, 48)        0                                  \n",
      "dropout_1 (Dropout)           (None, 32, 48, 48)        0                                  \n",
      "conv2d_2 (Conv2D)             (None, 64, 48, 48)        51200            (64, 32, 5, 5)    \n",
      "maxpooling2d_2 (Pooling)      (None, 64, 24, 24)        0                                  \n",
      "dropout_2 (Dropout)           (None, 64, 24, 24)        0                                  \n",
      "conv2d_3 (Conv2D)             (None, 128, 24, 24)       204800           (128, 64, 5, 5)   \n",
      "maxpooling2d_3 (Pooling)      (None, 128, 12, 12)       0                                  \n",
      "dropout_3 (Dropout)           (None, 128, 12, 12)       0                                  \n",
      "conv2d_4 (Conv2D)             (None, 256, 12, 12)       819200           (256, 128, 5, 5)  \n",
      "maxpooling2d_4 (Pooling)      (None, 256, 6, 6)         0                                  \n",
      "dropout_4 (Dropout)           (None, 256, 6, 6)         0                                  \n",
      "conv2d_5 (Conv2D)             (None, 512, 6, 6)         3276800          (512, 256, 5, 5)  \n",
      "maxpooling2d_5 (Pooling)      (None, 512, 3, 3)         0                                  \n",
      "dropout_5 (Dropout)           (None, 512, 3, 3)         0                                  \n",
      "flatten_1 (Flatten)           (None, 4608)              0                                  \n",
      "dense_1 (Dense)               (None, 600)               2764800          (4608, 600)       \n",
      "dense_2 (Dense)               (None, 600)               360000           (600, 600)        \n",
      "dense_3 (Dense)               (None, 600)               360000           (600, 600)        \n",
      "dense_4 (Dense)               (None, 600)               360000           (600, 600)        \n",
      "dense_5 (Dense)               (None, 4 keypoints)       2400             (600, 4 keypoints)\n",
      "===========================================================================================\n",
      "Toal params: 8,200,000\n",
      "Trainable params: 8,200,000\n",
      "Non-trainable params: 0\n"
     ]
    }
   ],
   "source": [
    "## Architecture\n",
    "\n",
    "print(\"Layer (type)                  Output Shape              Param #          Param Shape       \")\n",
    "print(\"===========================================================================================\")\n",
    "print(\"conv2d_1 (Conv2D)             (None, 32, 96, 96)        800              (32, 1, 5, 5)     \")\n",
    "print(\"maxpooling2d_1 (Pooling)      (None, 32, 48, 48)        0                                  \")\n",
    "print(\"dropout_1 (Dropout)           (None, 32, 48, 48)        0                                  \") \n",
    "print(\"conv2d_2 (Conv2D)             (None, 64, 48, 48)        51200            (64, 32, 5, 5)    \")\n",
    "print(\"maxpooling2d_2 (Pooling)      (None, 64, 24, 24)        0                                  \")\n",
    "print(\"dropout_2 (Dropout)           (None, 64, 24, 24)        0                                  \")\n",
    "print(\"conv2d_3 (Conv2D)             (None, 128, 24, 24)       204800           (128, 64, 5, 5)   \")\n",
    "print(\"maxpooling2d_3 (Pooling)      (None, 128, 12, 12)       0                                  \")\n",
    "print(\"dropout_3 (Dropout)           (None, 128, 12, 12)       0                                  \")\n",
    "print(\"conv2d_4 (Conv2D)             (None, 256, 12, 12)       819200           (256, 128, 5, 5)  \")\n",
    "print(\"maxpooling2d_4 (Pooling)      (None, 256, 6, 6)         0                                  \")\n",
    "print(\"dropout_4 (Dropout)           (None, 256, 6, 6)         0                                  \")\n",
    "print(\"conv2d_5 (Conv2D)             (None, 512, 6, 6)         3276800          (512, 256, 5, 5)  \")\n",
    "print(\"maxpooling2d_5 (Pooling)      (None, 512, 3, 3)         0                                  \")\n",
    "print(\"dropout_5 (Dropout)           (None, 512, 3, 3)         0                                  \")\n",
    "print(\"flatten_1 (Flatten)           (None, 4608)              0                                  \")\n",
    "print(\"dense_1 (Dense)               (None, 600)               2764800          (4608, 600)       \")\n",
    "print(\"dense_2 (Dense)               (None, 600)               360000           (600, 600)        \")\n",
    "print(\"dense_3 (Dense)               (None, 600)               360000           (600, 600)        \")\n",
    "print(\"dense_4 (Dense)               (None, 600)               360000           (600, 600)        \")\n",
    "print(\"dense_5 (Dense)               (None, 4 keypoints)       2400             (600, 4 keypoints)\")\n",
    "print(\"===========================================================================================\")\n",
    "print(\"Toal params: 8,200,000\")\n",
    "print(\"Trainable params: 8,200,000\")\n",
    "print(\"Non-trainable params: 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.sandbox.cuda): The cuda backend is deprecated and will be removed in the next release (v0.10).  Please switch to the gpuarray backend. You can get more information about how to switch at this URL:\n",
      " https://github.com/Theano/Theano/wiki/Converting-to-the-new-gpu-back-end%28gpuarray%29\n",
      "\n",
      "/home/ec2-user/anaconda3/lib/python3.6/site-packages/theano/sandbox/cuda/__init__.py:556: UserWarning: Theano flag device=gpu* (old gpu back-end) only support floatX=float32. You have floatX=float64. Use the new gpu back-end with device=cuda* for that value of floatX.\n",
      "  warnings.warn(msg)\n",
      "Using gpu device 0: GRID K520 (CNMeM is disabled, cuDNN 5103)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gpu\n",
      "float64\n",
      "3.6.1 |Anaconda 4.4.0 (64-bit)| (default, May 11 2017, 13:09:58) \n",
      "[GCC 4.4.7 20120313 (Red Hat 4.4.7-1)]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import sys\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "from six.moves import cPickle\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "import time\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.pool import pool_2d\n",
    "\n",
    "import conv_net_helper as helper\n",
    "\n",
    "print(theano.config.device)\n",
    "print(theano.config.floatX)\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Training Data and Create Training and Dev sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 6042\n",
      "Number of dev examples: 1007\n"
     ]
    }
   ],
   "source": [
    "TRAIN = \"../../../data/facial_keypoints/training.csv\"\n",
    "TEST = \"../../../data/facial_keypoints/test.csv\"\n",
    "\n",
    "rawdata = helper.load_data(TRAIN)\n",
    "X, Y = helper.loadXY(rawdata)\n",
    "num_dev = int(len(X)/7)\n",
    "train_data, train_labels = X[num_dev:], Y[num_dev:]\n",
    "dev_data, dev_labels = X[:num_dev], Y[:num_dev]\n",
    "\n",
    "print(\"Number of training examples:\", len(train_data))\n",
    "print(\"Number of dev examples:\", len(dev_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Column names of keypoint sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['eye_ct', 'eye_cr', 'eyebrow', 'nose', 'mouth_cr', 'mouth_ct_top', 'mouth_ct_bottom'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_keypoints = (rawdata.columns.values).tolist()[:-1]\n",
    "cols_dict = {\n",
    "    \"eye_ct\" : [\"left_eye_center_x\", \"left_eye_center_y\",\n",
    "                \"right_eye_center_x\", \"right_eye_center_y\"],\n",
    "    \"eye_cr\" : [\"left_eye_inner_corner_x\", \"left_eye_inner_corner_y\",\n",
    "                \"left_eye_outer_corner_x\", \"left_eye_outer_corner_y\",\n",
    "                \"right_eye_inner_corner_x\", \"right_eye_inner_corner_y\",\n",
    "                \"right_eye_outer_corner_x\", \"right_eye_outer_corner_y\"],\n",
    "    \"eyebrow\" : [\"left_eyebrow_inner_end_x\", \"left_eyebrow_inner_end_y\",\n",
    "                 \"left_eyebrow_outer_end_x\", \"left_eyebrow_outer_end_y\",\n",
    "                 \"right_eyebrow_inner_end_x\", \"right_eyebrow_inner_end_y\",\n",
    "                 \"right_eyebrow_outer_end_x\", \"right_eyebrow_outer_end_y\"],\n",
    "    \"nose\" : [\"nose_tip_x\", \"nose_tip_y\"],\n",
    "    \"mouth_cr\" : [\"mouth_left_corner_x\", \"mouth_left_corner_y\",\n",
    "                           \"mouth_right_corner_x\", \"mouth_right_corner_y\"],\n",
    "    \"mouth_ct_top\" : [\"mouth_center_top_lip_x\", \"mouth_center_top_lip_y\"],\n",
    "    \"mouth_ct_bottom\" : [\"mouth_center_bottom_lip_x\", \"mouth_center_bottom_lip_y\"]\n",
    "}\n",
    "cols_dict.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Traing Data - for keypoint sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data_sep = [0 for i in cols_dict.keys()]\n",
    "train_labels_sep = [0 for i in cols_dict.keys()]\n",
    "for i, key in enumerate(cols_dict.keys()):\n",
    "    train_data_sep[i], train_labels_sep[i] = helper.subset_data(train_data,\n",
    "                                                                train_labels,\n",
    "                                                                full_keypoints,\n",
    "                                                                cols_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Subset Dev Data - for keypoint sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_data_sep = [0 for i in cols_dict.keys()]\n",
    "dev_labels_sep = [0 for i in cols_dict.keys()]\n",
    "for i, key in enumerate(cols_dict.keys()):\n",
    "    dev_data_sep[i], dev_labels_sep[i] = helper.subset_data(dev_data,\n",
    "                                                                dev_labels,\n",
    "                                                                full_keypoints,\n",
    "                                                                cols_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape training and dev data into tensor 4D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training set shape, dev set shape\n",
      "(6030, 1, 96, 96) (1003, 1, 96, 96)\n",
      "(1917, 1, 96, 96) (330, 1, 96, 96)\n",
      "(1865, 1, 96, 96) (325, 1, 96, 96)\n",
      "(6042, 1, 96, 96) (1007, 1, 96, 96)\n",
      "(1927, 1, 96, 96) (336, 1, 96, 96)\n",
      "(1938, 1, 96, 96) (337, 1, 96, 96)\n",
      "(6017, 1, 96, 96) (999, 1, 96, 96)\n"
     ]
    }
   ],
   "source": [
    "print(\"training set shape, dev set shape\")\n",
    "for i in range(len(train_data_sep)):\n",
    "    train_data_sep[i] = helper.load_2d_images(train_data_sep[i], 96)\n",
    "    dev_data_sep[i] = helper.load_2d_images(dev_data_sep[i], 96)\n",
    "    print(train_data_sep[i].shape, dev_data_sep[i].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build separate CNN models\n",
    "\n",
    "- 0: eye center\n",
    "- 1: eye corner\n",
    "- 2: eyebrow\n",
    "- 3: nose\n",
    "- 4: mouse corner\n",
    "- 5: mouse center top\n",
    "- 6: mouse center bottom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "numModels = len(train_data_sep)\n",
    "cnns = [0. for i in range(numModels)]\n",
    "\n",
    "for i in range(numModels):\n",
    "    numClasses = train_labels_sep[i][1].size\n",
    "    cnns[i] = helper.convNetBuilder(numClasses, patchSize = [5,5], \n",
    "                                   featureMapLayers = [32,64,128,256,512],\n",
    "                                   numHiddenNodes = 600, numNNLayer = 5,\n",
    "                                   imageWidth = 96, poolingSize = 2,\n",
    "                                   train_dropout_rate = [0.2,0.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------\n",
      "(32, 1, 5, 5)\n",
      "(64, 32, 5, 5)\n",
      "(128, 64, 5, 5)\n",
      "(256, 128, 5, 5)\n",
      "(512, 256, 5, 5)\n",
      "(4608, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 4)\n",
      "-----------------\n",
      "(32, 1, 5, 5)\n",
      "(64, 32, 5, 5)\n",
      "(128, 64, 5, 5)\n",
      "(256, 128, 5, 5)\n",
      "(512, 256, 5, 5)\n",
      "(4608, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 8)\n",
      "-----------------\n",
      "(32, 1, 5, 5)\n",
      "(64, 32, 5, 5)\n",
      "(128, 64, 5, 5)\n",
      "(256, 128, 5, 5)\n",
      "(512, 256, 5, 5)\n",
      "(4608, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 8)\n",
      "-----------------\n",
      "(32, 1, 5, 5)\n",
      "(64, 32, 5, 5)\n",
      "(128, 64, 5, 5)\n",
      "(256, 128, 5, 5)\n",
      "(512, 256, 5, 5)\n",
      "(4608, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 2)\n",
      "-----------------\n",
      "(32, 1, 5, 5)\n",
      "(64, 32, 5, 5)\n",
      "(128, 64, 5, 5)\n",
      "(256, 128, 5, 5)\n",
      "(512, 256, 5, 5)\n",
      "(4608, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 4)\n",
      "-----------------\n",
      "(32, 1, 5, 5)\n",
      "(64, 32, 5, 5)\n",
      "(128, 64, 5, 5)\n",
      "(256, 128, 5, 5)\n",
      "(512, 256, 5, 5)\n",
      "(4608, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 2)\n",
      "-----------------\n",
      "(32, 1, 5, 5)\n",
      "(64, 32, 5, 5)\n",
      "(128, 64, 5, 5)\n",
      "(256, 128, 5, 5)\n",
      "(512, 256, 5, 5)\n",
      "(4608, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 600)\n",
      "(600, 2)\n"
     ]
    }
   ],
   "source": [
    "## Validate the parameters' matrix shape\n",
    "for i in range(numModels):\n",
    "    print(\"-----------------\")\n",
    "    for j in range(len(cnns[i].params)):\n",
    "        print(cnns[i].params[j].get_value().shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training multiple CNN models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_result = [ [] for i in range(numModels) ]\n",
    "val_result = [ [] for i in range(numModels) ]\n",
    "model_name = [\"eye center\", \"eye corner\", \"eyebrow\", \"nose\",\n",
    "              \"mouth corner\", \"mouth center top\", \"mouth center bottom\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### first training trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ======================================================\n",
      "CNN Model 1  -  eye center keypoint prediction\n",
      "\n",
      "Epoch: 1 / 1000\n",
      "training time: 880.30395484 s, ----- loss: 0.0158258945051 , RMSE: 6.03844855403\n",
      "validation loss: 1.21478302394 , val RMSE: 52.9042539609\n",
      "\n",
      "Epoch: 2 / 1000\n",
      "training time: 873.586210012 s, ----- loss: 0.0158604053171 , RMSE: 6.0450288544\n",
      "validation loss: 1.17748362595 , val RMSE: 52.0857204443\n",
      "\n",
      "Epoch: 3 / 1000\n",
      "training time: 882.13487339 s, ----- loss: 0.0184171028083 , RMSE: 6.51406208677\n",
      "validation loss: 1.17156091347 , val RMSE: 51.9545603833\n",
      "\n",
      "Epoch: 4 / 1000\n",
      "training time: 760.372305155 s, ----- loss: 0.0107313276227 , RMSE: 4.97242182872\n",
      "validation loss: 1.10928991295 , val RMSE: 50.5549597906\n",
      "\n",
      "Epoch: 5 / 1000\n",
      "training time: 497.775071859 s, ----- loss: 0.0141021642948 , RMSE: 5.70012162459\n",
      "validation loss: 1.02869498341 , val RMSE: 48.6838088257\n",
      "\n",
      "Epoch: 6 / 1000\n",
      "training time: 495.802038193 s, ----- loss: 0.0138427848243 , RMSE: 5.64745750185\n",
      "validation loss: 1.09384210481 , val RMSE: 50.2017152046\n",
      "\n",
      "Epoch: 7 / 1000\n",
      "training time: 499.545372725 s, ----- loss: 0.0127157801339 , RMSE: 5.41268486322\n",
      "validation loss: 1.08143088215 , val RMSE: 49.9160971277\n",
      "\n",
      "Epoch: 8 / 1000\n",
      "training time: 499.361257792 s, ----- loss: 0.012259247389 , RMSE: 5.31463131217\n",
      "validation loss: 1.02216870312 , val RMSE: 48.5291324051\n",
      "\n",
      "Epoch: 9 / 1000\n",
      "training time: 502.715925217 s, ----- loss: 0.0126337765512 , RMSE: 5.39520353405\n",
      "validation loss: 1.00244672331 , val RMSE: 48.0586854845\n",
      "\n",
      "Epoch: 10 / 1000\n",
      "training time: 504.249852419 s, ----- loss: 0.0108598493988 , RMSE: 5.00210885675\n",
      "validation loss: 1.02313190672 , val RMSE: 48.5519918551\n",
      "\n",
      "Epoch: 11 / 1000\n",
      "training time: 497.356733084 s, ----- loss: 0.0130831615879 , RMSE: 5.4903191436\n",
      "validation loss: 0.937887968591 , val RMSE: 46.4854157735\n",
      "\n",
      "Epoch: 12 / 1000\n",
      "training time: 496.87281394 s, ----- loss: 0.0112039933045 , RMSE: 5.08074803288\n",
      "validation loss: 0.955725670166 , val RMSE: 46.9253869889\n",
      "\n",
      "Epoch: 13 / 1000\n",
      "training time: 498.260141373 s, ----- loss: 0.0117444151012 , RMSE: 5.2018393279\n",
      "validation loss: 0.971279207094 , val RMSE: 47.3056792906\n",
      "\n",
      "Epoch: 14 / 1000\n",
      "training time: 498.009502888 s, ----- loss: 0.0119924592357 , RMSE: 5.25648419375\n",
      "validation loss: 0.943413262459 , val RMSE: 46.6221423436\n",
      "\n",
      "Epoch: 15 / 1000\n",
      "training time: 495.761597872 s, ----- loss: 0.011951031415 , RMSE: 5.24739710526\n",
      "validation loss: 0.920107861895 , val RMSE: 46.0426814359\n",
      "\n",
      "Epoch: 16 / 1000\n",
      "training time: 501.378343105 s, ----- loss: 0.0128845906011 , RMSE: 5.4484949064\n",
      "validation loss: 0.913278605278 , val RMSE: 45.871493398\n",
      "\n",
      "Epoch: 17 / 1000\n",
      "training time: 499.20994997 s, ----- loss: 0.0108507180077 , RMSE: 5.00000542898\n",
      "validation loss: 0.938703064929 , val RMSE: 46.5056110765\n",
      "\n",
      "Epoch: 18 / 1000\n",
      "training time: 521.89216733 s, ----- loss: 0.0117542625117 , RMSE: 5.20401967972\n",
      "validation loss: 0.922654650225 , val RMSE: 46.1063587168\n",
      "\n",
      "Epoch: 19 / 1000\n",
      "training time: 500.733460188 s, ----- loss: 0.0132676873782 , RMSE: 5.52890149301\n",
      "validation loss: 0.93209826806 , val RMSE: 46.3417134945\n",
      "\n",
      "Epoch: 20 / 1000\n",
      "training time: 499.645501137 s, ----- loss: 0.0106187145766 , RMSE: 4.94626307272\n",
      "validation loss: 0.916153966744 , val RMSE: 45.9436474322\n",
      "\n",
      "Epoch: 21 / 1000\n",
      "training time: 505.119935274 s, ----- loss: 0.0119502129248 , RMSE: 5.24721741295\n",
      "validation loss: 0.898843098578 , val RMSE: 45.5075213467\n",
      "\n",
      "Epoch: 22 / 1000\n",
      "training time: 498.386717796 s, ----- loss: 0.0118501897414 , RMSE: 5.22521168606\n",
      "validation loss: 0.892310874752 , val RMSE: 45.3418598585\n",
      "\n",
      "Epoch: 23 / 1000\n",
      "training time: 504.985873222 s, ----- loss: 0.0120190511273 , RMSE: 5.26230878962\n",
      "validation loss: 0.896892810743 , val RMSE: 45.4581239819\n",
      "\n",
      "Epoch: 24 / 1000\n",
      "training time: 500.845844507 s, ----- loss: 0.0118018297394 , RMSE: 5.21453887891\n",
      "validation loss: 0.903493066973 , val RMSE: 45.6250811101\n",
      "\n",
      "Epoch: 25 / 1000\n",
      "training time: 504.396137238 s, ----- loss: 0.0116186611513 , RMSE: 5.17391489035\n",
      "validation loss: 0.87840254784 , val RMSE: 44.9871033767\n",
      "\n",
      "Epoch: 26 / 1000\n",
      "training time: 501.787165403 s, ----- loss: 0.0122419027347 , RMSE: 5.31087035248\n",
      "validation loss: 0.890763825553 , val RMSE: 45.3025369496\n",
      "\n",
      "Epoch: 27 / 1000\n",
      "training time: 499.415185928 s, ----- loss: 0.0103457772137 , RMSE: 4.88228130082\n",
      "validation loss: 0.911018910776 , val RMSE: 45.8147091056\n",
      "\n",
      "Epoch: 28 / 1000\n",
      "training time: 498.838460207 s, ----- loss: 0.0117882305637 , RMSE: 5.21153367241\n",
      "validation loss: 0.871995008613 , val RMSE: 44.8227230302\n",
      "\n",
      "Epoch: 29 / 1000\n",
      "training time: 498.622589588 s, ----- loss: 0.0132257230114 , RMSE: 5.52015088728\n",
      "validation loss: 0.90163294852 , val RMSE: 45.578090278\n",
      "\n",
      "Epoch: 30 / 1000\n",
      "training time: 500.032067776 s, ----- loss: 0.0122926658566 , RMSE: 5.32187017256\n",
      "validation loss: 0.868882242679 , val RMSE: 44.7426495319\n",
      "\n",
      "Epoch: 31 / 1000\n",
      "training time: 500.454759836 s, ----- loss: 0.0122215235744 , RMSE: 5.30644799421\n",
      "validation loss: 0.889304147414 , val RMSE: 45.265403518\n",
      "\n",
      "Epoch: 32 / 1000\n",
      "training time: 501.110673666 s, ----- loss: 0.0104234117072 , RMSE: 4.90056533202\n",
      "validation loss: 0.856439041365 , val RMSE: 44.421116052\n",
      "\n",
      "Epoch: 33 / 1000\n",
      "training time: 499.670721769 s, ----- loss: 0.0107425387123 , RMSE: 4.97501851184\n",
      "validation loss: 0.868352764583 , val RMSE: 44.7290148517\n",
      "\n",
      "Epoch: 34 / 1000\n",
      "training time: 499.9289608 s, ----- loss: 0.0124347923524 , RMSE: 5.35254720484\n",
      "validation loss: 0.885882302878 , val RMSE: 45.1782339831\n",
      "\n",
      "Epoch: 35 / 1000\n",
      "training time: 497.45222187 s, ----- loss: 0.0106394753883 , RMSE: 4.95109596905\n",
      "validation loss: 0.860987817513 , val RMSE: 44.538926026\n",
      "\n",
      "Epoch: 36 / 1000\n",
      "training time: 501.888676405 s, ----- loss: 0.0116128064065 , RMSE: 5.17261113564\n",
      "validation loss: 0.882621091493 , val RMSE: 45.0949996651\n",
      "\n",
      "Epoch: 37 / 1000\n",
      "training time: 497.068642139 s, ----- loss: 0.0119781561285 , RMSE: 5.25334861971\n",
      "validation loss: 0.874037160555 , val RMSE: 44.8751781937\n",
      "\n",
      "Epoch: 38 / 1000\n",
      "training time: 499.06804204 s, ----- loss: 0.0120069444518 , RMSE: 5.25965778515\n",
      "validation loss: 0.860217946525 , val RMSE: 44.5190088478\n",
      "\n",
      "Epoch: 39 / 1000\n",
      "training time: 498.57877326 s, ----- loss: 0.0110503874577 , RMSE: 5.04579951074\n",
      "validation loss: 0.857198857113 , val RMSE: 44.4408164505\n",
      "\n",
      "Epoch: 40 / 1000\n",
      "training time: 497.129533291 s, ----- loss: 0.0135063418034 , RMSE: 5.57840582202\n",
      "validation loss: 0.845098311534 , val RMSE: 44.1260298438\n",
      "\n",
      "Epoch: 41 / 1000\n",
      "training time: 494.57916975 s, ----- loss: 0.0124333494548 , RMSE: 5.35223664872\n",
      "validation loss: 0.851754048925 , val RMSE: 44.2994506594\n",
      "\n",
      "Epoch: 42 / 1000\n",
      "training time: 494.946375132 s, ----- loss: 0.0123469183252 , RMSE: 5.3336010182\n",
      "validation loss: 0.853044254698 , val RMSE: 44.3329895543\n",
      "\n",
      "Epoch: 43 / 1000\n",
      "training time: 496.880859375 s, ----- loss: 0.0121260444705 , RMSE: 5.28567937544\n",
      "validation loss: 0.839033750361 , val RMSE: 43.9674170362\n",
      "\n",
      "Epoch: 44 / 1000\n",
      "training time: 500.009337902 s, ----- loss: 0.011468980399 , RMSE: 5.14047963124\n",
      "validation loss: 0.85034918759 , val RMSE: 44.2629023925\n",
      "\n",
      "Epoch: 45 / 1000\n",
      "training time: 503.701588631 s, ----- loss: 0.0125492186723 , RMSE: 5.37711817063\n",
      "validation loss: 0.846720749688 , val RMSE: 44.1683665906\n",
      "\n",
      "Epoch: 46 / 1000\n",
      "training time: 505.343939781 s, ----- loss: 0.0107041088807 , RMSE: 4.9661118454\n",
      "validation loss: 0.856922578979 , val RMSE: 44.4336541595\n",
      "\n",
      "Epoch: 47 / 1000\n",
      "training time: 502.275499821 s, ----- loss: 0.0121075592894 , RMSE: 5.28164904199\n",
      "validation loss: 0.861626000519 , val RMSE: 44.5554295816\n",
      "\n",
      "Epoch: 48 / 1000\n",
      "training time: 505.363003969 s, ----- loss: 0.0119987487706 , RMSE: 5.25786241427\n",
      "validation loss: 0.85643184725 , val RMSE: 44.4209294822\n",
      "\n",
      "Epoch: 49 / 1000\n",
      "training time: 504.238309622 s, ----- loss: 0.0126721528342 , RMSE: 5.40339153958\n",
      "validation loss: 0.867929999024 , val RMSE: 44.7181251592\n",
      "\n",
      "Epoch: 50 / 1000\n",
      "training time: 500.754664898 s, ----- loss: 0.0121594634117 , RMSE: 5.29295793489\n",
      "validation loss: 0.861968335498 , val RMSE: 44.5642799222\n",
      "\n",
      "Epoch: 51 / 1000\n",
      "training time: 500.004766226 s, ----- loss: 0.011887331812 , RMSE: 5.23339397475\n",
      "validation loss: 0.855150908514 , val RMSE: 44.3876975435\n",
      "\n",
      "Epoch: 52 / 1000\n",
      "training time: 500.927703381 s, ----- loss: 0.0116802535684 , RMSE: 5.1876106467\n",
      "validation loss: 0.871960421195 , val RMSE: 44.8218340815\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 53 / 1000\n",
      "training time: 499.498436928 s, ----- loss: 0.0118288135669 , RMSE: 5.22049676353\n",
      "validation loss: 0.861996218366 , val RMSE: 44.5650006969\n",
      "\n",
      "Epoch: 54 / 1000\n",
      "training time: 503.695280552 s, ----- loss: 0.0117094853514 , RMSE: 5.19409802079\n",
      "validation loss: 0.857425588494 , val RMSE: 44.4466934191\n",
      "\n",
      "Epoch: 55 / 1000\n",
      "training time: 497.90859127 s, ----- loss: 0.0105760187908 , RMSE: 4.93630907602\n",
      "validation loss: 0.847507095229 , val RMSE: 44.1888713073\n"
     ]
    }
   ],
   "source": [
    "rounds = 1000\n",
    "alpha_schedule = np.linspace(0.3, 0.0001, rounds)\n",
    "\n",
    "for i, model in enumerate(cnns):\n",
    "    print(\"\\n ======================================================\")\n",
    "    print(\"CNN Model\", (i+1), \" - \", model_name[i], \"keypoint prediction\")\n",
    "    train_result[i] , val_result[i] = model.SGD(train_data_sep[i], train_labels_sep[i],\n",
    "                                                update_rule = \"backprop\",\n",
    "                                                epochs = rounds, \n",
    "                                                miniBatchSize = 10,\n",
    "                                                learning_rate = 0.05,\n",
    "                                                learningRateSchedule = alpha_schedule,\n",
    "                                                validation = [dev_data_sep[i],\n",
    "                                                              dev_labels_sep[i]]\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try again with less epochs\n",
    "\n",
    "- rmsprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " ======================================================\n",
      "CNN Model 1  -  eye center keypoint prediction\n",
      "\n",
      "Epoch: 1 / 20\n",
      "training time: 641.937942505 s, ----- loss: 32.7267844569 , RMSE: 274.595177286\n",
      "validation loss: 23.4298188629 , val RMSE: 232.340919039\n",
      "\n",
      "Epoch: 2 / 20\n",
      "training time: 953.477121115 s, ----- loss: 140.578078584 , RMSE: 569.115008638\n",
      "validation loss: 124.701971006 , val RMSE: 536.016176246\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-2fe6c61cc07e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                 \u001b[0mlearningRateSchedule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha_schedule\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m                                                 validation = [dev_data_sep[i],\n\u001b[0;32m---> 14\u001b[0;31m                                                               dev_labels_sep[i]]\n\u001b[0m\u001b[1;32m     15\u001b[0m                                                )\n",
      "\u001b[0;32m/home/ec2-user/repo/models/facial_keypoints/conv_net_helper.py\u001b[0m in \u001b[0;36mSGD\u001b[0;34m(self, X, Y, update_rule, epochs, miniBatchSize, learning_rate, learningRateSchedule, validation)\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0mepochStartTime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    281\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatchStart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatchEnd\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 282\u001b[0;31m                 \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchStart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatchStart\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatchEnd\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    283\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0mtrain_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcost\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ec2-user/anaconda3/lib/python3.6/site-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    882\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    883\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "rounds = 20\n",
    "alpha_schedule = np.linspace(0.3, 0.0001, rounds)\n",
    "\n",
    "for i, model in enumerate(cnns):\n",
    "    print(\"\\n ======================================================\")\n",
    "    print(\"CNN Model\", (i+1), \" - \", model_name[i], \"keypoint prediction\")\n",
    "    train_result[i] , val_result[i] = model.SGD(train_data_sep[i], train_labels_sep[i],\n",
    "                                                update_rule = \"rmsprop\",\n",
    "                                                epochs = rounds, \n",
    "                                                miniBatchSize = 10,\n",
    "                                                learning_rate = 0.05,\n",
    "                                                learningRateSchedule = alpha_schedule,\n",
    "                                                validation = [dev_data_sep[i],\n",
    "                                                              dev_labels_sep[i]]\n",
    "                                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_result' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-72375a776b75>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mhelper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_performance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0mval_result\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train_result' is not defined"
     ]
    }
   ],
   "source": [
    "for i in range(7):\n",
    "    helper.plot_performance(train_result[i] , val_result[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(numModels):\n",
    "    for layer in range(len(cnns[i].params)):\n",
    "        filename = model_name[i] + \"_layer\" + str(layer+1)\n",
    "        helper.save_layer_params(cnns[i].params[layer], filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.0039484 , -0.01108056,  0.00097547, ...,  0.00673776,\n",
       "        -0.00781311, -0.00604274],\n",
       "       [-0.01168752,  0.00146486,  0.00517273, ...,  0.00331349,\n",
       "        -0.01609198,  0.00706688],\n",
       "       [-0.00588158,  0.00856659, -0.00125814, ..., -0.00328748,\n",
       "         0.0118611 ,  0.00234903],\n",
       "       ..., \n",
       "       [-0.01497844, -0.00012292, -0.01610636, ...,  0.00627014,\n",
       "         0.00585229, -0.00109457],\n",
       "       [-0.01884747, -0.0079815 , -0.01920352, ..., -0.00610651,\n",
       "        -0.00692251,  0.00126688],\n",
       "       [-0.00646328, -0.00138179, -0.00709273, ...,  0.02022066,\n",
       "         0.00733202, -0.00276212]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "helper.load_saved_params(\"eye_ct_layer9_weights\").get_value()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----------------------------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
